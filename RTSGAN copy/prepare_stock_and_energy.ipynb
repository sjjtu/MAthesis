{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open 1 None continuous\n",
      "High 1 None continuous\n",
      "Low 1 None continuous\n",
      "Close 1 None continuous\n",
      "Adj_Close 1 None continuous\n",
      "Volume 1 None continuous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1-asd-arch/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3661\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from stock_energy.missingprocessor import Processor\n",
    "import pickle\n",
    "\n",
    "data_path = \"../TimeGAN/data\"\n",
    "loc = \"stock\"\n",
    "seq_len = 24\n",
    "df = pd.read_csv('{}/{}_data.csv'.format(data_path,loc), sep = \",\")\n",
    "types = [\"continuous\" for i in range(len(df.columns))]\n",
    "\n",
    "P = Processor(types)\n",
    "# Flip the data to make chronological data\n",
    "ori_data = P.fit_transform(df)\n",
    "ori_data = ori_data[::-1]\n",
    "\n",
    "temp_data = [ori_data[i:i + seq_len] for i in range(0, len(ori_data) - seq_len)]    \n",
    "\n",
    "from fastNLP import DataSet\n",
    "dataset = DataSet({\"seq_len\": [seq_len] * len(temp_data), \"dyn\": temp_data, \"sta\":[0]*len(temp_data)})\n",
    "dic = {\n",
    "    \"train_set\": dataset,\n",
    "    \"dynamic_processor\": P,\n",
    "    \"static_processor\": Processor([])\n",
    "}\n",
    "print(P.dim, len(temp_data))\n",
    "from utils.general import make_sure_path_exists\n",
    "make_sure_path_exists(\"./data\")\n",
    "#with open(\"./data/{}.pkl\".format(loc), \"wb\") as f:\n",
    "#    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3685, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--noise-dim'], dest='noise_dim', nargs=None, const=None, default=96, type=<class 'int'>, choices=None, help='dim of WGAN noise state', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import collections\n",
    "import logging\n",
    "import math\n",
    "import os,sys,time\n",
    "import random\n",
    "from sys import maxsize\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.general import init_logger, make_sure_path_exists\n",
    "sys.path.append('./stock_energy/')\n",
    "\n",
    "from aegan import AeGAN\n",
    "\n",
    "DEBUG_SCALE = 512\n",
    "# ===-----------------------------------------------------------------------===\n",
    "# Argument parsing\n",
    "# ===-----------------------------------------------------------------------===\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataset\", default=\"stock\", dest=\"dataset\", help=\".pkl file to use\")                  \n",
    "parser.add_argument(\"--devi\", default=\"0\", dest=\"devi\", help=\"gpu\")\n",
    "parser.add_argument(\"--epochs\", default=1000, dest=\"epochs\", type=int,\n",
    "                    help=\"Number of full passes through training set for autoencoder\")\n",
    "parser.add_argument(\"--iterations\", default=15000, dest=\"iterations\", type=int,\n",
    "                    help=\"Number of iterations through training set for WGAN\")\n",
    "parser.add_argument(\"--d-update\", default=5, dest=\"d_update\", type=int,\n",
    "                    help=\"discriminator updates per generator update\")\n",
    "parser.add_argument(\"--log-dir\", default=\"../stock_result\", dest=\"log_dir\",\n",
    "                    help=\"Directory where to write logs / serialized models\")\n",
    "parser.add_argument(\"--task-name\", default=time.strftime(\"%Y-%m-%d-%H-%M-%S\"), dest=\"task_name\",\n",
    "                    help=\"Name for this task, use a comprehensive one\")\n",
    "parser.add_argument(\"--python-seed\", dest=\"python_seed\", type=int, default=random.randrange(maxsize),\n",
    "                    help=\"Random seed of Python and NumPy\")\n",
    "parser.add_argument(\"--debug\", dest=\"debug\", default=False, action=\"store_true\", help=\"Debug mode\")\n",
    "parser.add_argument(\"--eval-ae\", dest=\"eval_ae\", default=False, action=\"store_true\", help=\"evaluate autoencoder\")\n",
    "parser.add_argument(\"--fix-ae\", dest=\"fix_ae\", default=None, help=\"Test mode\")\n",
    "parser.add_argument(\"--fix-gan\", dest=\"fix_gan\", default=None, help=\"Test mode\")\n",
    "parser.add_argument(\"--ae-batch-size\", default=128, dest=\"ae_batch_size\", type=int,\n",
    "                    help=\"Minibatch size for autoencoder\")\n",
    "parser.add_argument(\"--gan-batch-size\", default=512, dest=\"gan_batch_size\", type=int,\n",
    "                    help=\"Minibatch size for WGAN\")\n",
    "parser.add_argument(\"--embed-dim\", default=32, dest=\"embed_dim\", type=int, help=\"dim of hidden state\")\n",
    "parser.add_argument(\"--hidden-dim\", default=32, dest=\"hidden_dim\", type=int, help=\"dim of GRU hidden state\")\n",
    "parser.add_argument(\"--layers\", default=3, dest=\"layers\", type=int, help=\"layers\")\n",
    "parser.add_argument(\"--ae-lr\", default=1e-3, dest=\"ae_lr\", type=float, help=\"autoencoder learning rate\")\n",
    "parser.add_argument(\"--weight-decay\", default=0, dest=\"weight_decay\", type=float, help=\"weight decay\")\n",
    "parser.add_argument(\"--scale\", default=1, dest=\"scale\", type=float, help=\"scale\")\n",
    "parser.add_argument(\"--dropout\", default=0.0, dest=\"dropout\", type=float,\n",
    "                    help=\"Amount of dropout(not keep rate, but drop rate) to apply to embeddings part of graph\")\n",
    "\n",
    "parser.add_argument(\"--gan-lr\", default=1e-4, dest=\"gan_lr\", type=float, help=\"WGAN learning rate\")\n",
    "parser.add_argument(\"--gan-alpha\", default=0.99, dest=\"gan_alpha\", type=float, help=\"for RMSprop\")\n",
    "parser.add_argument(\"--noise-dim\", default=96, dest=\"noise_dim\", type=int, help=\"dim of WGAN noise state\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1-asd-arch/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/ipykernel_launcher.py --f=/home/user1-asd-arch/.local/share/jupyter/runtime/kernel-v2-1882Jz2z0o2suugs.json\n",
      "\n",
      "Namespace(ae_batch_size=128, ae_lr=0.001, d_update=5, dataset='stock', debug=False, devi='0', dropout=0.0, embed_dim=32, epochs=1000, eval_ae=False, fix_ae=None, fix_gan=None, gan_alpha=0.99, gan_batch_size=512, gan_lr=0.0001, hidden_dim=32, iterations=15000, layers=3, log_dir='../stock_result', noise_dim=96, python_seed=2345370441991939620, scale=1, task_name='2024-01-16-22-56-24', weight_decay=0)\n",
      "Python random seed: 2345370441991939620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset', 'devi', 'epochs', 'iterations', 'd_update', 'log_dir', 'task_name', 'python_seed', 'debug', 'eval_ae', 'fix_ae', 'fix_gan', 'ae_batch_size', 'gan_batch_size', 'embed_dim', 'hidden_dim', 'layers', 'ae_lr', 'weight_decay', 'scale', 'dropout', 'gan_lr', 'gan_alpha', 'noise_dim', 'static_processor', 'dynamic_processor', 'root_dir', 'logger', 'device'])\n",
      "torch.Size([512, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x128 and 32x21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4731/3047489890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAeGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0msyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Thesis/RTSGAN/stock_energy/aegan.py\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(self, dataset, iterations, d_update)\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq_len\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mreal_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                     \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0mdloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;31m#y = d_real.new_full(size=d_real.size(), fill_value=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Thesis/RTSGAN/stock_energy/gan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-b8C0A6mP/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x128 and 32x21)"
     ]
    }
   ],
   "source": [
    "options = parser.parse_args(\"\")\n",
    "\n",
    "task_name = options.task_name\n",
    "root_dir = \"{}/{}\".format(options.log_dir, task_name)\n",
    "make_sure_path_exists(root_dir)\n",
    "\n",
    "devices=[int(x) for x in options.devi]\n",
    "device = torch.device(\"cuda:{}\".format(devices[0]))  \n",
    "\n",
    "# ===-----------------------------------------------------------------------===\n",
    "# Set up logging\n",
    "# ===-----------------------------------------------------------------------===\n",
    "logger = init_logger(root_dir)\n",
    "\n",
    "# ===-----------------------------------------------------------------------===\n",
    "# Log some stuff about this run\n",
    "# ===-----------------------------------------------------------------------===\n",
    "logger.info(' '.join(sys.argv))\n",
    "logger.info('')\n",
    "logger.info(options)\n",
    "\n",
    "if options.debug:\n",
    "    print(\"DEBUG MODE\")\n",
    "    options.epochs=11\n",
    "    options.iterations=1\n",
    "\n",
    "random.seed(options.python_seed)\n",
    "np.random.seed(options.python_seed % (2 ** 32 - 1))\n",
    "logger.info('Python random seed: {}'.format(options.python_seed))\n",
    "\n",
    "# ===-----------------------------------------------------------------------===\n",
    "# Read in dataset\n",
    "# ===-----------------------------------------------------------------------===\n",
    "dataset = dic\n",
    "train_set=dataset[\"train_set\"]\n",
    "dynamic_processor=dataset[\"dynamic_processor\"]\n",
    "static_processor=dataset[\"static_processor\"]\n",
    "train_set.set_input(\"sta\",\"dyn\",\"seq_len\")\n",
    "                    \n",
    "if options.debug:\n",
    "    train_set = train_set[0:DEBUG_SCALE]\n",
    "    \n",
    "# ===-----------------------------------------------------------------------===\n",
    "# Build model and trainer\n",
    "# ===-----------------------------------------------------------------------===\n",
    "\n",
    "params=vars(options)\n",
    "params[\"static_processor\"]=static_processor\n",
    "params[\"dynamic_processor\"]=dynamic_processor\n",
    "params[\"root_dir\"]=root_dir\n",
    "params[\"logger\"]=logger\n",
    "params[\"device\"]=device\n",
    "print(params.keys())\n",
    "\n",
    "syn = AeGAN((static_processor, dynamic_processor), params)\n",
    "\n",
    "syn.train_gan(train_set, options.iterations, options.d_update)\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(\"Generating data!\")\n",
    "result = syn.synthesize(len(train_set))\n",
    "#print(result[0], np.array(result[0]).shape)\n",
    "with open(\"{}/data\".format(root_dir), \"wb\") as f:\n",
    "    pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
