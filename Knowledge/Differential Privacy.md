Formalization of privacy in database. Intuitively, an algorithm is differentiable private if the risk to somebody's privacy is "essentially" not increased by participating in a statistical data base.

might be good for understanding: [phd thesis](https://www.scss.tcd.ie/Doug.Leith/pubs/Naoise_thesis.pdf) by naoise holohan

review by OG Cynthia Dwork [Form foundation for private data analysis](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/01/dwork_cacm.pdf) and here [Algorithmic Foundations of DP](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) 

Privacy requires randomization proof: https://www.youtube.com/watch?v=HoCasrGCKs4

used by Apple, Google, US Census data

good resource for basic theorems and understandable proofs: 
- http://www.gautamkamath.com/CS860notes/lec4.pdf
- https://cs-people.bu.edu/gaboardi/teaching/cse711Spring2016/Lecture1.pdf