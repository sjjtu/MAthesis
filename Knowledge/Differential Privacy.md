Formalization of privacy in database. Intuitively, an algorithm is differentiable private if the risk to somebody's privacy is "essentially" not increased by participating in a statistical data base.

might be good for understanding: [phd thesis](https://www.scss.tcd.ie/Doug.Leith/pubs/Naoise_thesis.pdf) by naoise holohan

review by OG Cynthia Dwork [Form foundation for private data analysis](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/01/dwork_cacm.pdf) and here [Algorithmic Foundations of DP](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) 

Privacy requires randomization proof: https://www.youtube.com/watch?v=HoCasrGCKs4

used by Apple, Google, US Census data

good resource for basic theorems and understandable proofs: 
- http://www.gautamkamath.com/CS860notes/lec4.pdf
- https://cs-people.bu.edu/gaboardi/teaching/cse711Spring2016/Lecture1.pdf
- https://privacytools.seas.harvard.edu/files/privacytools/files/complexityprivacy_1_01.pdf

good resource easy to understand example for randomized reponse:
- [ ] https://accuracyandprivacy.substack.com/p/differential-privacy-an-easy-case

Pytorch implementation of DP:
- https://opacus.ai/

Auditing of DP:
- https://www.floriantramer.com/publications/