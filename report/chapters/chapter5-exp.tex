\section{Experiment}
In this chapter we describe the experiments conducted on heartbeat data taken from the MIT-BIH Arrhythmia data set. Afterwards we present the results and draw insights. The aim is to assess the utility of synthetic data generated by the two algorithms mentioned in chapter \ref{chapter4}. The utility is measured in the downstream task of arrhythmia detection. We are testing differentially private and non-private versions of the models and compare them to a baseline model that is trained on the original data.

\subsection{Data Set and Experiment setup}
The MIT-BIH is a commonly used benchmark data set for arrhythmia detection. It contains two channel ECG data collected in the 1980s from some 47 patients by the Arrhythmia Laboratory of Boston's Beth Israel Hospital (BIH; now the Beth Israel Deaconess Medical Center). 23 patients were chosen at random from a pool of over 4000 thousand patients, whereas the rest was chosen to include examples of clinically important but statistically uncommon arrhythmias. Hence, the proportion of arrhythmias in the whole data set is much larger than in reality. Studies suggest a percentage between 1.5\% and 5\% of patients with arrhythmias depending on the reference group \colorbox{red}{REF???}. 

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{../images/placeholder.png}
    \caption[short]{Excerpt from one ECG data sample, where the R peaks are highlighted}
\end{figure}

\colorbox{red}{description of heartbeat complex}

\colorbox{red}{what is aheartbeat arrhythmia how relate to anomaly detection}

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{../images/placeholder.png}
    \caption[short]{heart beat samples}
\end{figure}

Before we proceed with the training, we need to preprocess the data. Firstly, since the information contained in both channels are identical, one channel is discarded. We are roughly following the steps from \colorbox{red}{???REF}. This involves normalising the data and extracting single heartbeats from the sequence. To this end, we employ the commonly used QRS detector \colorbox{red}{REF} that can detect the R peaks. This is already implemented in the \texttt{wfdb} package for \texttt{python}. Then, from every peak we consider 90 time steps before and after that peak. This gives one heartbeat with sequence length 180. The associated beat type can then be extracted from the labelled data set. In total this gives \colorbox{red}{???} single heartbeats each of length 180. 

\begin{table}[h]
    \centering
    \begin{tabular}{c|c}
        & \\ 
        &
    \end{tabular}
    \caption{Train-test-validation split of the preprocessed and extracted heartbeats}
    \label{tab:train-test-val}
\end{table}

All preprocessing tasks and subsequent models are implemented in \texttt{python 3.10} on a machine running Arch Linux 6.15 with 16 GB of RAM, an Nvidia RTX 3070 8GB, and AMD 7700 processor with 8 cores / 16 threads.


\subsection{Baseline Model}

\subsection{Data generation}

\subsection{Private Data Generation}


\subsection{Polluted Data Set}

\subsection{Results}