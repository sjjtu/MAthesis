\section{Theoretical background on Differential Privacy}

In this chapter we briefly describe and derive the most important results from Cynthia Dwork's work on differential privacy that was first introduced in ??. This summary heavily relies on her writings in her as well as lecture notes from ????.

\subsection{Defining differential privacy}
Differential privacy (DP) should be understood as an agreement between the data holder and the data subject: the latter should not be "affected, adversely or otherwise, by allowing [her] data to be used in any study or analysis, no matter what other studies, data sets or information sources are available" \cite{}. This addresses the paradox of learning something useful about a population while learning nothing about the individuals


\begin{ex}[Randomised response]
    \colorbox{red}{citation needed} ??? proposes the following random answering procedure: In a study where participants are asked to answer with "Yes" or "No" whether they have engaged in an illegal or embarrassing activity $A$, they should:
    \begin{enumerate}
        \item Flip a coin
        \item If the coin shows tails, then the participant should respond truthfully.
        \item If the coin shows head, then the participant should flip the coin a second time and answer "Yes" if the second coin shows head and "no" otherwise.
    \end{enumerate}
    This procedure ensures participants' privacy by "plausible deniability"; each participant's answer has non-zero probability of being truthful or not. By understanding the probabilities of the noise generation process, the data analyst can estimate the true number of "yes" and "no" answers. To this end, let $p$ b the true percentage of "yes" answers, $N$ the total number of participants, $n_{true}$ the true number of "yes" responses and $\hat{n}_{obs}$ the observed number of "yes" responses. We assume a fair coin with equal probability of showing heads or tails. Then the expected number of "yes" answers after applying the described procedure is:
    \begin{align}
        \mathbb{E}("Yes") = \frac{1}{4} n_{true} + \frac{1}{4} (N-n_{true}) + \frac{1}{2} n_{true} = \frac{1}{4} N + \frac{n_{true}}{2}
    \end{align}
    We can estimate this using the $\hat{n}_{obs} \approx \mathbb{E}("Yes") = \frac{1}{4} N + \frac{n_{true}}{2}$ and finally solving for $n_{true}$ yields the estimate:
    \begin{align}
        \hat{n_{true}} = 2 \hat{n}_{obs} - \frac{1}{2} N
    \end{align}
\end{ex}


\begin{definition}[Probability Simplex]
    Given a discrete set $B$, the probability simplex over $B$ is defined as the set
    \begin{align}
        \Delta(B) = \left\{ x \in \mathbb{R}^{|B|}, x_i \ge 0 \text{ and } \sum_i x_i = 1  \right\}
    \end{align}
\end{definition}

\begin{definition}(Randomised Algorithm)
    A randomized algorithm $\mathcal{M}$ with domain $A$ and discrete range $B$ is associated with a mapping $M: A \rightarrow \Delta(B)$. On input $a\in A$ algorithm $\mathcal{M}$ outputs $\mathcal{M}(a)=b$ with probability $(M(a))_b$
\end{definition}

\begin{definition}[Histogram representation of a data base]
 Given a set $\mathcal{X}$, the universe of all possible records", the histrogram representation of a database $x$ is the vector
 \begin{align}
     x \in \mathbb{N}^{|\mathcal{X}|}
 \end{align}
in which each entry $x_i$ represents the number of elements in database $x$ of type $i\in \mathcal{X}$.
\end{definition}

\begin{definition}[$l_1$-norm of a database in histogram representation]
    The $l_1$-norm of a database is a measure of the size of the database and defined as:
    \begin{align}
        ||x||_1 = \sum_{i=1}^{|\mathcal{X}|} |x_i|
    \end{align}
\end{definition}

This immediately gives rise to a notion of distance between two databases $x$ and $y$, namely:
\begin{align}
    ||x-y||_1   = \sum_{i=1}^{|\mathcal{X}|} |x_i-y_i|
\end{align}
which basically counts the number of different entries.

Now we are ready to give the general definition of differential privacy:
\begin{definition}[$(\epsilon, \delta)$-DP]
    A randomised algorithm $\mathcal{M}$ with domain $\mathbb{N}^{|\mathcal{X}|}$ is $(\epsilon, \delta)$- differentially private if for all outcomes $S \subset ran \mathcal{M}$ and for all databases $x,y \in \mathbb{N}^{|\mathcal{X}|}$, such that $||x-y||_1$ (i. e. they only differ in one element) we have
    \begin{align}
        \mathbb{P}(\mathcal{M}(x) \in S) \le e^\epsilon \cdot \mathbb{P}(\mathcal{M}(y) \in S) + \delta 
    \end{align}
    where the probability is taken over the randomness of $\mathcal{M}$. If $\delta=0$, we say $\mathcal{M}$ is $\epsilon$-differentially private.
\end{definition}

\colorbox{red}{why $e^\epsilon$}

\begin{ex}[Randomised response revisited]
    
\end{ex}

\subsection{Important results for Differential Privacy}

\begin{thm}[DP requires randomisation]
    Any non-trivial DP-mechanism requires randomisation.
\end{thm}
\begin{proof}
    TBA
\end{proof}

\begin{thm}[Post-processing]
    Let $\mathcal{M}: \mathbb{N}^{|\mathcal{X}|} \rightarrow R$ be a randomised algorithm that is $(\epsilon, \delta)$- DP. Further let $f: R \rightarrow R'$ an arbitrary function. Then $f \circ \mathcal{M}$ is also $(\epsilon, \delta)$ -DP.
\end{thm}
\begin{proof}
    First fix data sets $x,y \in \mathbb{N}^{|\mathcal{X}|}$, s. t. $||x-y||_1\le 1$ and outcome $S' \subseteq R'$. Define a set $S=\left\{r\in R: f(r) \in S'\right\}$. Then we have:
    \begin{align}
        \mathbb{P}(f(\mathcal{M}(x))\in S') &= \mathbb{P}(\mathcal{M}(x)\in S) \nonumber \\
        &\le e^\epsilon \cdot \mathbb{P}(\mathcal{M}(y)\in S) + \delta \nonumber \\
        &= e^\epsilon \cdot \mathbb{P}(f(\mathcal{M}(y))\in S') + \delta
    \end{align}
    where the inequality follows from the $(\epsilon, \delta)-DP$ of $\mathcal{M}$.
\end{proof}

\begin{thm}[Group privacy]
    Let $\mathcal{M}: \mathbb{N}^{|\mathcal{X}|} \rightarrow R$ be a randomised algorithm that is $(\epsilon, \delta)$- DP, then $\mathcal{M}$ is $(k\epsilon, k e^{k\epsilon} \delta)$- DP for groups of size $k$, i. e. it holds for databases $x,y \in \mathbb{N}^{|\mathcal{X}|}$ such that $||x-y||_1\le k$ and for all $S \subseteq R$:
    \begin{align}
        \mathbb{P}(\mathcal{M}(x) \in S) \le e^{k\epsilon} \cdot \mathbb{P}(\mathcal{M}(y) \in S) + k\delta 
    \end{align}
\end{thm}
\begin{proof}
    First fix data sets $x,y \in \mathbb{N}^{|\mathcal{X}|}$, s. t. $||x-y||_1\le k$ and outcome $S \subseteq R$. Now there exists a series of databases $z_0,..., z_k$, such that $x=z_0$ and $y=z_k$ and $|| z_{i+1} - z_i||_1 \le 1$, i. e. we can find a series of databases that transforms $x$ into $y$ by removing or adding one record at a time. Then we have:
    \begin{align}
        \mathbb{P}(\mathcal{M}(x)\in S) &= \mathbb{P}(\mathcal{M}(z_0)\in S) \nonumber \\
        &\le e^\epsilon \cdot \mathbb{P}(\mathcal{M}(z_1)\in S) + \delta \nonumber \\
        &\le e^\epsilon \left( e^\epsilon \cdot \mathbb{P}(\mathcal{M}(z_2)\in S) + \delta \right) + \delta \nonumber \\
        &\le ... \nonumber \\
        &= k e^\epsilon \cdot \mathbb{P}(f(\mathcal{M}(y))\in S') + k e^{k \epsilon} \delta
    \end{align}
\end{proof}

\begin{thm}[Standard composition]
    Let $\mathcal{M}_1: \mathbb{N}^{|\mathcal{X}|} \rightarrow R_1$ and $\mathcal{M}_2: \mathbb{N}^{|\mathcal{X}|} \rightarrow R_2$ be two randomised algorithms that are $(\epsilon_1, \delta_1)$- and $(\epsilon_2, \delta_2)$ DP, then their composition defined by $\mathcal{M}_{12}: \mathbb{N}^{|\mathcal{X}|} \rightarrow R_1 \times R_2$, $\mathcal{M}_{12}(x)=(\mathcal{M}_{1}(x), \mathcal{M}_{2}(x))$ is $(\epsilon_1+\epsilon_2, \delta_1+\delta_2)$ DP.
\end{thm}
\begin{proof}
    TBA
\end{proof}

\subsection{Example of DP-mechanism: Laplace mechanism}